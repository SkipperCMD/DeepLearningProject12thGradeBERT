{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7ezJRthX7AU"
      },
      "outputs": [],
      "source": [
        "#Basics\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "#tf libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "#torch libraries\n",
        "import torch\n",
        "from torch import cuda\n",
        "\n",
        "#Time related libraries\n",
        "import datetime\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "#General libraries\n",
        "import collections\n",
        "import math\n",
        "import random\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Dealing with files, data and general stuff\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "#May be used but very unlikely.\n",
        "from subprocess import check_output\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from numba import jit, cuda #Former way of GPU acceleration in my project.\n",
        "\n",
        "#Transformers Library. Taken from \"Hugging Face\".\n",
        "from transformers import BertConfig, BertModel, BertTokenizer, BertForMaskedLM, BertTokenizerFast, pipeline\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "#Optimizers taken from the \"Transformers\" Library that I have mentioned above as well.\n",
        "from transformers import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVG5MTZ6X7AX"
      },
      "outputs": [],
      "source": [
        "#Loading The Tokenizer & Model Path\n",
        "path_to_tokenizer = \"G:/VisualStudioCodeG/Resources/Tokenizers/bookcorpus/Run1/BERTbookcorpusTokenizerRun1-vocab.txt\"\n",
        "path_to_model = \"G:/VisualStudioCodeG/Resources/Models/bookcorpus/Run1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksczJnhmX7AY",
        "outputId": "6f0c5040-6faf-493b-cab8-33a63cf70ba0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Cthulhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1706: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(path_to_tokenizer, clean_text=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcHK3h7gX7AY"
      },
      "outputs": [],
      "source": [
        "model = BertForMaskedLM.from_pretrained(path_to_model)\n",
        "#model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TGV2EZwX7AZ"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BLMmkIFX7AZ"
      },
      "outputs": [],
      "source": [
        "ExampleSentence = \"How [MASK] you doing?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaGKkPAOX7Aa",
        "outputId": "9da4bcd6-99b6-47cb-f2ec-2ed91c05293a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "are\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(ExampleSentence, return_tensors=\"pt\") #Tokenizing the sentence after modifications.\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "        #Using the Model to get the \"raw prediction vector\" which will be passed to the softmax function when predicting the missing word.\n",
        "\n",
        "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0] #Retrieving the index of the [MASK]\n",
        "\n",
        "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
        "PredWord = tokenizer.decode(predicted_token_id)\n",
        "\n",
        "print(PredWord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3SDHQV6X7Ab",
        "outputId": "e83c31df-51c2-45c0-8af7-559459df0ed8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'score': 0.21366684138774872,\n",
              "  'token': 309,\n",
              "  'token_str': 'are',\n",
              "  'sequence': 'how are you doing?'},\n",
              " {'score': 0.14240136742591858,\n",
              "  'token': 215,\n",
              "  'token_str': 'is',\n",
              "  'sequence': 'how is you doing?'},\n",
              " {'score': 0.09299653768539429,\n",
              "  'token': 287,\n",
              "  'token_str': 'about',\n",
              "  'sequence': 'how about you doing?'},\n",
              " {'score': 0.07042302936315536,\n",
              "  'token': 179,\n",
              "  'token_str': 'do',\n",
              "  'sequence': 'how do you doing?'},\n",
              " {'score': 0.04870709031820297,\n",
              "  'token': 142,\n",
              "  'token_str': 'was',\n",
              "  'sequence': 'how was you doing?'}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(f'How {pipe.tokenizer.mask_token} you doing?')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
